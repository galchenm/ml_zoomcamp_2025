{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04aa0812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91ab1af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('course_lead_scoring.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9f7cd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
       "0      paid_ads         NaN                         1        79450.0   \n",
       "1  social_media      retail                         1        46992.0   \n",
       "2        events  healthcare                         5        78796.0   \n",
       "3      paid_ads      retail                         2        83843.0   \n",
       "4      referral   education                         3        85012.0   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  converted  \n",
       "0        unemployed  south_america                  4        0.94          1  \n",
       "1          employed  south_america                  1        0.80          0  \n",
       "2        unemployed      australia                  3        0.69          1  \n",
       "3               NaN      australia                  1        0.87          0  \n",
       "4     self_employed         europe                  3        0.62          1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eba03845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 128\n",
       "industry                    134\n",
       "number_of_courses_viewed      0\n",
       "annual_income               181\n",
       "employment_status           100\n",
       "location                     63\n",
       "interaction_count             0\n",
       "lead_score                    0\n",
       "converted                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "246d6e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                  object\n",
       "industry                     object\n",
       "number_of_courses_viewed      int64\n",
       "annual_income               float64\n",
       "employment_status            object\n",
       "location                     object\n",
       "interaction_count             int64\n",
       "lead_score                  float64\n",
       "converted                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10b8f560",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = list(df.dtypes[df.dtypes == 'object'].index)\n",
    "numerical_columns = list(df.dtypes[df.dtypes != 'object'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a917a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in categorical_columns:\n",
    "    df[c] = df[c].fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bdd2033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>referral</td>\n",
       "      <td>manufacturing</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>north_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>referral</td>\n",
       "      <td>technology</td>\n",
       "      <td>3</td>\n",
       "      <td>65259.0</td>\n",
       "      <td>student</td>\n",
       "      <td>europe</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>technology</td>\n",
       "      <td>1</td>\n",
       "      <td>45688.0</td>\n",
       "      <td>student</td>\n",
       "      <td>north_america</td>\n",
       "      <td>3</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>referral</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>71016.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>north_america</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>organic_search</td>\n",
       "      <td>finance</td>\n",
       "      <td>3</td>\n",
       "      <td>92855.0</td>\n",
       "      <td>student</td>\n",
       "      <td>north_america</td>\n",
       "      <td>3</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1462 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lead_source       industry  number_of_courses_viewed  annual_income  \\\n",
       "0           paid_ads             NA                         1        79450.0   \n",
       "1       social_media         retail                         1        46992.0   \n",
       "2             events     healthcare                         5        78796.0   \n",
       "3           paid_ads         retail                         2        83843.0   \n",
       "4           referral      education                         3        85012.0   \n",
       "...              ...            ...                       ...            ...   \n",
       "1457        referral  manufacturing                         1            NaN   \n",
       "1458        referral     technology                         3        65259.0   \n",
       "1459        paid_ads     technology                         1        45688.0   \n",
       "1460        referral             NA                         5        71016.0   \n",
       "1461  organic_search        finance                         3        92855.0   \n",
       "\n",
       "     employment_status       location  interaction_count  lead_score  \\\n",
       "0           unemployed  south_america                  4        0.94   \n",
       "1             employed  south_america                  1        0.80   \n",
       "2           unemployed      australia                  3        0.69   \n",
       "3                   NA      australia                  1        0.87   \n",
       "4        self_employed         europe                  3        0.62   \n",
       "...                ...            ...                ...         ...   \n",
       "1457     self_employed  north_america                  4        0.53   \n",
       "1458           student         europe                  2        0.24   \n",
       "1459           student  north_america                  3        0.02   \n",
       "1460     self_employed  north_america                  0        0.25   \n",
       "1461           student  north_america                  3        0.41   \n",
       "\n",
       "      converted  \n",
       "0             1  \n",
       "1             0  \n",
       "2             1  \n",
       "3             0  \n",
       "4             1  \n",
       "...         ...  \n",
       "1457          1  \n",
       "1458          1  \n",
       "1459          1  \n",
       "1460          1  \n",
       "1461          1  \n",
       "\n",
       "[1462 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cfd12e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in numerical_columns:\n",
    "    df[n] = df[n].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab111689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>referral</td>\n",
       "      <td>manufacturing</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>north_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>referral</td>\n",
       "      <td>technology</td>\n",
       "      <td>3</td>\n",
       "      <td>65259.0</td>\n",
       "      <td>student</td>\n",
       "      <td>europe</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>technology</td>\n",
       "      <td>1</td>\n",
       "      <td>45688.0</td>\n",
       "      <td>student</td>\n",
       "      <td>north_america</td>\n",
       "      <td>3</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>referral</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>71016.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>north_america</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>organic_search</td>\n",
       "      <td>finance</td>\n",
       "      <td>3</td>\n",
       "      <td>92855.0</td>\n",
       "      <td>student</td>\n",
       "      <td>north_america</td>\n",
       "      <td>3</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1462 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lead_source       industry  number_of_courses_viewed  annual_income  \\\n",
       "0           paid_ads             NA                         1        79450.0   \n",
       "1       social_media         retail                         1        46992.0   \n",
       "2             events     healthcare                         5        78796.0   \n",
       "3           paid_ads         retail                         2        83843.0   \n",
       "4           referral      education                         3        85012.0   \n",
       "...              ...            ...                       ...            ...   \n",
       "1457        referral  manufacturing                         1            0.0   \n",
       "1458        referral     technology                         3        65259.0   \n",
       "1459        paid_ads     technology                         1        45688.0   \n",
       "1460        referral             NA                         5        71016.0   \n",
       "1461  organic_search        finance                         3        92855.0   \n",
       "\n",
       "     employment_status       location  interaction_count  lead_score  \\\n",
       "0           unemployed  south_america                  4        0.94   \n",
       "1             employed  south_america                  1        0.80   \n",
       "2           unemployed      australia                  3        0.69   \n",
       "3                   NA      australia                  1        0.87   \n",
       "4        self_employed         europe                  3        0.62   \n",
       "...                ...            ...                ...         ...   \n",
       "1457     self_employed  north_america                  4        0.53   \n",
       "1458           student         europe                  2        0.24   \n",
       "1459           student  north_america                  3        0.02   \n",
       "1460     self_employed  north_america                  0        0.25   \n",
       "1461           student  north_america                  3        0.41   \n",
       "\n",
       "      converted  \n",
       "0             1  \n",
       "1             0  \n",
       "2             1  \n",
       "3             0  \n",
       "4             1  \n",
       "...         ...  \n",
       "1457          1  \n",
       "1458          1  \n",
       "1459          1  \n",
       "1460          1  \n",
       "1461          1  \n",
       "\n",
       "[1462 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2291a93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 0\n",
       "industry                    0\n",
       "number_of_courses_viewed    0\n",
       "annual_income               0\n",
       "employment_status           0\n",
       "location                    0\n",
       "interaction_count           0\n",
       "lead_score                  0\n",
       "converted                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572ba02b",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "What is the most frequent observation (mode) for the column industry?\n",
    "\n",
    "* NA\n",
    "* technology\n",
    "* healthcare\n",
    "* retail\n",
    "\n",
    "Answ: retail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "617990ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "industry\n",
       "retail           203\n",
       "finance          200\n",
       "other            198\n",
       "healthcare       187\n",
       "education        187\n",
       "technology       179\n",
       "manufacturing    174\n",
       "NA               134\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.industry.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ff0c59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 - Mode of 'industry': retail\n"
     ]
    }
   ],
   "source": [
    "industry_mode = df['industry'].mode()[0]\n",
    "print(\"Q1 - Mode of 'industry':\", industry_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ba4b5d",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "Create the correlation matrix for the numerical features of your dataset. In a correlation matrix, you compute the correlation coefficient between every pair of features.\n",
    "\n",
    "What are the two features that have the biggest correlation?\n",
    "\n",
    "* interaction_count and lead_score\n",
    "* number_of_courses_viewed and lead_score\n",
    "* number_of_courses_viewed and interaction_count\n",
    "* annual_income and interaction_count\n",
    "\n",
    "Only consider the pairs above when answering this question.\n",
    "\n",
    "ANSW: annual_income and interaction_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9624cb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df[numerical_columns].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4f44b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009770</td>\n",
       "      <td>-0.023565</td>\n",
       "      <td>-0.004879</td>\n",
       "      <td>0.435914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_income</th>\n",
       "      <td>0.009770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027036</td>\n",
       "      <td>0.015610</td>\n",
       "      <td>0.053131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interaction_count</th>\n",
       "      <td>-0.023565</td>\n",
       "      <td>0.027036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>0.374573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead_score</th>\n",
       "      <td>-0.004879</td>\n",
       "      <td>0.015610</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.193673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>converted</th>\n",
       "      <td>0.435914</td>\n",
       "      <td>0.053131</td>\n",
       "      <td>0.374573</td>\n",
       "      <td>0.193673</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          number_of_courses_viewed  annual_income  \\\n",
       "number_of_courses_viewed                  1.000000       0.009770   \n",
       "annual_income                             0.009770       1.000000   \n",
       "interaction_count                        -0.023565       0.027036   \n",
       "lead_score                               -0.004879       0.015610   \n",
       "converted                                 0.435914       0.053131   \n",
       "\n",
       "                          interaction_count  lead_score  converted  \n",
       "number_of_courses_viewed          -0.023565   -0.004879   0.435914  \n",
       "annual_income                      0.027036    0.015610   0.053131  \n",
       "interaction_count                  1.000000    0.009888   0.374573  \n",
       "lead_score                         0.009888    1.000000   0.193673  \n",
       "converted                          0.374573    0.193673   1.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c1f0f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Candidate pair correlations:\n",
      "interaction_count and lead_score: 0.009888\n",
      "number_of_courses_viewed and lead_score: -0.004879\n",
      "number_of_courses_viewed and interaction_count: -0.023565\n",
      "annual_income and interaction_count: 0.027036\n",
      "\n",
      "Q2 - best pair (largest absolute correlation): ('annual_income', 'interaction_count')\n"
     ]
    }
   ],
   "source": [
    "candidates = [\n",
    "    ('interaction_count','lead_score'),\n",
    "    ('number_of_courses_viewed','lead_score'),\n",
    "    ('number_of_courses_viewed','interaction_count'),\n",
    "    ('annual_income','interaction_count')\n",
    "]\n",
    "\n",
    "print(\"\\nCandidate pair correlations:\")\n",
    "pair_corrs = {}\n",
    "for a,b in candidates:\n",
    "    val = corr.loc[a,b]\n",
    "    pair_corrs[(a,b)] = val\n",
    "    print(f\"{a} and {b}: {val:.6f}\")\n",
    "\n",
    "# choose the pair with the largest absolute correlation\n",
    "best_pair = max(pair_corrs.items(), key=lambda kv: abs(kv[1]))[0]\n",
    "print(\"\\nQ2 - best pair (largest absolute correlation):\", best_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "423e39dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interaction_count and lead_score: 0.009888\n",
      "number_of_courses_viewed and lead_score: -0.004879\n",
      "number_of_courses_viewed and interaction_count: -0.023565\n",
      "annual_income and interaction_count: 0.027036\n"
     ]
    }
   ],
   "source": [
    "for a,b in candidates:\n",
    "    val = df[a].corr(df[b])\n",
    "    print(f\"{a} and {b}: {val:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c163dc7e",
   "metadata": {},
   "source": [
    "# Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "509badad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88fc5600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes -> train: (876, 9) val: (293, 9) test: (293, 9)\n"
     ]
    }
   ],
   "source": [
    "df_model = df.copy()\n",
    "train_val, test = train_test_split(df_model, test_size=0.2, random_state=42, stratify=df_model['converted'])\n",
    "train, val = train_test_split(train_val, test_size=0.25, random_state=42, stratify=train_val['converted'])  # 0.25 * 0.8 = 0.2\n",
    "\n",
    "print(\"Shapes -> train:\", train.shape, \"val:\", val.shape, \"test:\", test.shape)\n",
    "\n",
    "X_train = train.drop(columns=['converted']).reset_index(drop=True)\n",
    "y_train = train['converted'].reset_index(drop=True)\n",
    "X_val = val.drop(columns=['converted']).reset_index(drop=True)\n",
    "y_val = val['converted'].reset_index(drop=True)\n",
    "X_test = test.drop(columns=['converted']).reset_index(drop=True)\n",
    "y_test = test['converted'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b19b72",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "* Calculate the mutual information score between converted and other categorical variables in the dataset. Use the training set only.\n",
    "* Round the scores to 2 decimals using round(score, 2).\n",
    "\n",
    "\n",
    "\n",
    "Which of these variables has the biggest mutual information score?\n",
    "\n",
    "* industry\n",
    "* location\n",
    "* lead_source\n",
    "* employment_status\n",
    "\n",
    "ANSW: lead_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92500668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0d26a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_info_churn_score(series):\n",
    "    return round(mutual_info_score(series, train.converted), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2eea6572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source          0.03\n",
       "industry             0.01\n",
       "employment_status    0.01\n",
       "location             0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi = train[categorical_columns].apply(mutual_info_churn_score)\n",
    "mi.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f663be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual information scores (rounded to 2 decimals):\n",
      "lead_source -> 0.03\n",
      "industry -> 0.01\n",
      "employment_status -> 0.01\n",
      "location -> 0.0\n",
      "\n",
      "Q3 - variable with biggest MI: lead_source\n"
     ]
    }
   ],
   "source": [
    "mi_scores = {}\n",
    "for c in categorical_columns:\n",
    "    mi = mutual_info_score(y_train, X_train[c])\n",
    "    mi_scores[c] = round(mi, 2)\n",
    "\n",
    "mi_sorted = sorted(mi_scores.items(), key=lambda kv: kv[1], reverse=True)\n",
    "print(\"Mutual information scores (rounded to 2 decimals):\")\n",
    "for k,v in mi_sorted:\n",
    "    print(k, \"->\", v)\n",
    "\n",
    "print(\"\\nQ3 - variable with biggest MI:\", mi_sorted[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d34c45b",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "* Now let's train a logistic regression.\n",
    "* Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "* Fit the model on the training dataset.\n",
    "* * To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "* * model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "* Calculate the accuracy on the validation dataset and round it to 2 decimal digits.\n",
    "\n",
    "What accuracy did you get?\n",
    "\n",
    "* 0.64\n",
    "* 0.74\n",
    "* 0.84\n",
    "* 0.94\n",
    "\n",
    "ANSW: 0.74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36600a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "train_dict = train[categorical_columns + numerical_columns].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "val_dict = val[categorical_columns + numerical_columns].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "761e3044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b4044ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5c1b2e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=42, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5da7a999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "converted_decision = (y_pred >= 0.5)\n",
    "\n",
    "round((y_val == converted_decision).mean(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "de4533cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q4 - Validation accuracy (rounded to 2 decimals): 0.73\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "X_train = train.drop(columns=['converted']).reset_index(drop=True)\n",
    "y_train = train['converted'].reset_index(drop=True)\n",
    "\n",
    "X_val = val.drop(columns=['converted']).reset_index(drop=True)\n",
    "y_val = val['converted'].reset_index(drop=True)\n",
    "\n",
    "X_test = test.drop(columns=['converted']).reset_index(drop=True)\n",
    "y_test = test['converted'].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Cell 6: prepare features (one-hot encode categorical features)\n",
    "def prepare_features(df_input, drop_cols=None):\n",
    "    df_temp = df_input.copy()\n",
    "    if drop_cols:\n",
    "        df_temp = df_temp.drop(columns=drop_cols)\n",
    "    cats = df_temp.select_dtypes(include=['object']).columns.tolist()\n",
    "    df_ohe = pd.get_dummies(df_temp, columns=cats, dummy_na=False)\n",
    "    return df_ohe\n",
    "\n",
    "# Prepare train/val matrices\n",
    "X_train_ohe = prepare_features(X_train)\n",
    "X_val_ohe = prepare_features(X_val)\n",
    "# align columns\n",
    "X_train_ohe, X_val_ohe = X_train_ohe.align(X_val_ohe, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Q4: train logistic regression with given params and compute validation accuracy (rounded to 2 decimals)\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train_ohe, y_train)\n",
    "val_pred = model.predict(X_val_ohe)\n",
    "val_acc = round(accuracy_score(y_val, val_pred), 2)\n",
    "print(\"Q4 - Validation accuracy (rounded to 2 decimals):\", val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d20abd",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "* Let's find the least useful feature using the feature elimination technique.\n",
    "* Train a model using the same features and parameters as in Q4 (without rounding).\n",
    "* Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "* For each feature, calculate the difference between the original accuracy and the accuracy without the feature.\n",
    "\n",
    "Which of following feature has the smallest difference?\n",
    "\n",
    "* 'industry'\n",
    "* 'employment_status'\n",
    "* 'lead_score'\n",
    "\n",
    "Note: The difference doesn't have to be positive.\n",
    "\n",
    "ANSW: employment_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c3dcc589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_selected_features(features):\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    train_dict = train[features].to_dict(orient='records')\n",
    "    X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "    val_dict = val[features].to_dict(orient='records')\n",
    "    X_val = dv.transform(val_dict)\n",
    "    model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    converted_decision = (y_pred >= 0.5)\n",
    "\n",
    "    return (y_val == converted_decision).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1c7e535b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78839590443686\n"
     ]
    }
   ],
   "source": [
    "features = categorical_columns + numerical_columns\n",
    "baseline = train_selected_features(features)\n",
    "print(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "96c473e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For category industry the difference of accuracy with the baseline is 0.0\n",
      "For category employment_status the difference of accuracy with the baseline is -0.010238907849829393\n",
      "For category lead_score the difference of accuracy with the baseline is -0.0034129692832765013\n"
     ]
    }
   ],
   "source": [
    "candidates = ['industry','employment_status','lead_score']\n",
    "\n",
    "for c in candidates:\n",
    "    new_features = [f for f in features if f!=c]\n",
    "    acc = train_selected_features(new_features)\n",
    "    print(f\"For category {c} the difference of accuracy with the baseline is {-acc + baseline}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "14dc2dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline validation accuracy (not rounded): 0.7303754266211604\n",
      "Removed industry: val acc = 0.730375, diff (orig - without) = 0.000000\n",
      "Removed employment_status: val acc = 0.733788, diff (orig - without) = -0.003413\n",
      "Removed lead_score: val acc = 0.730375, diff (orig - without) = 0.000000\n",
      "\n",
      "Q5 - least useful feature (smallest absolute difference): industry\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Feature elimination (fixed)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Ensure DataFrames\n",
    "X_train = train.drop(columns=['converted']).reset_index(drop=True)\n",
    "X_val = val.drop(columns=['converted']).reset_index(drop=True)\n",
    "\n",
    "# Baseline model\n",
    "orig_model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "orig_model.fit(X_train_ohe, y_train)\n",
    "orig_val_acc = accuracy_score(y_val, orig_model.predict(X_val_ohe))\n",
    "print(\"Baseline validation accuracy (not rounded):\", orig_val_acc)\n",
    "\n",
    "features_to_test = ['industry', 'employment_status', 'lead_score']\n",
    "acc_without = {}\n",
    "diffs = {}\n",
    "\n",
    "for feat in features_to_test:\n",
    "    Xtr = prepare_features(X_train, drop_cols=[feat])\n",
    "    Xva = prepare_features(X_val, drop_cols=[feat])\n",
    "    Xtr, Xva = Xtr.align(Xva, join='left', axis=1, fill_value=0)\n",
    "    m = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    m.fit(Xtr, y_train)\n",
    "    acc = accuracy_score(y_val, m.predict(Xva))\n",
    "    acc_without[feat] = acc\n",
    "    diffs[feat] = orig_val_acc - acc\n",
    "    print(f\"Removed {feat}: val acc = {acc:.6f}, diff (orig - without) = {diffs[feat]:.6f}\")\n",
    "\n",
    "least_useful = min(diffs.items(), key=lambda kv: abs(kv[1]))[0]\n",
    "print(\"\\nQ5 - least useful feature (smallest absolute difference):\", least_useful)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db75c838",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "* Now let's train a regularized logistic regression.\n",
    "* Let's try the following values of the parameter C: [0.01, 0.1, 1, 10, 100].\n",
    "* Train models using all the features as in Q4.\n",
    "* Calculate the accuracy on the validation dataset and round it to 3 decimal digits.\n",
    "\n",
    "Which of these C leads to the best accuracy on the validation set?\n",
    "\n",
    "* 0.01\n",
    "* 0.1\n",
    "* 1\n",
    "* 10\n",
    "* 100\n",
    "\n",
    "Note: If there are multiple options, select the smallest C.\n",
    "\n",
    "ANSW: 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "abd45a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_selected_features(features, C=1.0):\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    train_dict = train[features].to_dict(orient='records')\n",
    "    X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "    val_dict = val[features].to_dict(orient='records')\n",
    "    X_val = dv.transform(val_dict)\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    converted_decision = (y_pred >= 0.5)\n",
    "\n",
    "    return round((y_val == converted_decision).mean(),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f541feb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 0.01 the accuracy is 0.792\n",
      "for 0.1 the accuracy is 0.792\n",
      "for 1 the accuracy is 0.788\n",
      "for 10 the accuracy is 0.788\n",
      "for 100 the accuracy is 0.788\n"
     ]
    }
   ],
   "source": [
    "C = [0.01, 0.1, 1, 10, 100]\n",
    "features = categorical_columns + numerical_columns\n",
    "\n",
    "\n",
    "for c in C:\n",
    "    acc = train_selected_features(features, c)\n",
    "    print(f\"for {c} the accuracy is {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0e8e90f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy by C (rounded to 3 decimals):\n",
      "C=0.01 -> accuracy=0.734\n",
      "C=0.1 -> accuracy=0.73\n",
      "C=1 -> accuracy=0.73\n",
      "C=10 -> accuracy=0.73\n",
      "C=100 -> accuracy=0.73\n",
      "\n",
      "Q6 - best C (smallest among ties): 0.01 with accuracy 0.734\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: regularized logistic regression with different C values\n",
    "Cs = [0.01, 0.1, 1, 10, 100]\n",
    "accs_by_C = {}\n",
    "for C in Cs:\n",
    "    m = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42)\n",
    "    m.fit(X_train_ohe, y_train)\n",
    "    accs_by_C[C] = round(accuracy_score(y_val, m.predict(X_val_ohe)), 3)\n",
    "\n",
    "print(\"Validation accuracy by C (rounded to 3 decimals):\")\n",
    "for C,v in accs_by_C.items():\n",
    "    print(f\"C={C} -> accuracy={v}\")\n",
    "\n",
    "# Best C: if multiple equal, select smallest C among them\n",
    "best_acc = max(accs_by_C.values())\n",
    "best_Cs = [C for C,v in accs_by_C.items() if v == best_acc]\n",
    "best_C = min(best_Cs)\n",
    "print(\"\\nQ6 - best C (smallest among ties):\", best_C, \"with accuracy\", best_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14df8043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
